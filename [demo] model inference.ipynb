{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data import create_dataset, create_dataloader\n",
    "\n",
    "import torch\n",
    "import yaml\n",
    "from timm import create_model\n",
    "from models import MemSeg\n",
    "\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "cfg = yaml.load(open('./configs/capsule.yaml','r'), Loader=yaml.FullLoader)\n",
    "\n",
    "testset = create_dataset(\n",
    "    datadir                = cfg['DATASET']['datadir'],\n",
    "    target                 = cfg['DATASET']['target'], \n",
    "    train                  = False,\n",
    "    resize                 = cfg['DATASET']['resize'],\n",
    "    texture_source_dir     = cfg['DATASET']['texture_source_dir'],\n",
    "    structure_grid_size    = cfg['DATASET']['structure_grid_size'],\n",
    "    transparency_range     = cfg['DATASET']['transparency_range'],\n",
    "    perlin_scale           = cfg['DATASET']['perlin_scale'], \n",
    "    min_perlin_scale       = cfg['DATASET']['min_perlin_scale'], \n",
    "    perlin_noise_threshold = cfg['DATASET']['perlin_noise_threshold']\n",
    ")\n",
    "\n",
    "memory_bank = torch.load('./saved_model/MemSeg-capsule/memory_bank.pt')\n",
    "memory_bank.device = 'cpu'\n",
    "for k in memory_bank.memory_information.keys():\n",
    "    memory_bank.memory_information[k] = memory_bank.memory_information[k].cpu()\n",
    "\n",
    "feature_extractor = feature_extractor = create_model(\n",
    "    cfg['MODEL']['feature_extractor_name'], \n",
    "    pretrained    = True, \n",
    "    features_only = True\n",
    ")\n",
    "model = MemSeg(\n",
    "    memory_bank       = memory_bank,\n",
    "    feature_extractor = feature_extractor\n",
    ")\n",
    "\n",
    "model.load_state_dict(torch.load('./saved_model/MemSeg-capsule/best_model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_plot(idx, threshold):\n",
    "    input_i, mask_i, target_i = testset[idx]\n",
    "\n",
    "    output_i = model(input_i.unsqueeze(0)).detach()\n",
    "    output_i = torch.nn.functional.softmax(output_i, dim=1)\n",
    "\n",
    "    def minmax_scaling(img):\n",
    "        return (((img - img.min()) / (img.max() - img.min())) * 255).to(torch.uint8)\n",
    "\n",
    "    fig, ax = plt.subplots(1,4, figsize=(15,10))\n",
    "    \n",
    "    ax[0].imshow(minmax_scaling(input_i.permute(1,2,0)))\n",
    "    ax[0].set_title('Input: {}'.format('Normal' if target_i == 0 else 'Abnormal'))\n",
    "    ax[1].imshow(mask_i, cmap='gray')\n",
    "    ax[1].set_title('Ground Truth')\n",
    "    ax[2].imshow(output_i[0][1], cmap='gray')\n",
    "    ax[2].set_title('Predicted Mask')\n",
    "    ax[3].imshow(minmax_scaling(input_i.permute(1,2,0)), alpha=1)\n",
    "    ax[3].imshow(torch.where(output_i[0][1] > threshold, 1, 0), alpha=0.5)\n",
    "    ax[3].set_title(f'Predicted Mask(Threshold = {threshold})')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "file_list = widgets.Dropdown(\n",
    "    options=[(file_path, i) for i, file_path in enumerate(testset.file_list)],\n",
    "    value=0,\n",
    "    description='image:',\n",
    ")\n",
    "\n",
    "threshold = widgets.FloatSlider(\n",
    "    value=0.5,\n",
    "    min=0,\n",
    "    max=1.,\n",
    "    step=0.01,\n",
    "    description='Threshold:'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5141402b63745ccbc557664ca0cfff8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='image:', options=(('/datasets/MVTec/capsule/test/faulty_imprint/01â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.result_plot(idx, threshold)>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "widgets.interact(result_plot, idx=file_list, threshold=threshold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
